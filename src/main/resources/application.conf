akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = DEBUG
  logger-startup-timeout = 30s
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  log-dead-letters = 0
  log-dead-letters-during-shutdown = false
  
  actor {
    provider = "cluster"
    #"akka.cluster.ClusterActorRefProvider"

    default-dispatcher {
      fork-join-executor {
        parallelism-factor = 1.0
        parallelism-min = 2
        parallelism-max = 4
      }
    }
  }
  
  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 2551
    }
  }

  //"akka.tcp://blog@127.0.0.1:2552"
  cluster {
    seed-nodes = [
      #"akka.tcp://blog@127.0.0.1:2551"
      #"akka.tcp://ident@127.0.0.1:2551"


      # Key point is that we add a stub node as the first element in the list of seeds for seed-node. That prevents it from seeing itself on the first
      # place and thus from auto-creating a new cluster.

      #https://doc.akka.io/docs/akka-management/current/cluster-http-management.html#api-definition

      #

      # entry point
      "akka://table@127.0.0.3:2551" //a stub node address
      "akka://table@127.0.0.1:2551" //core ip

      # core
      #"akka.tcp://gt@127.0.0.2:2551" // entry point
      #"akka.tcp://gt@127.0.0.1:2551" // core ip

    ]

    auto-down-unreachable-after = 10s
    metrics.enabled = off

    sharding {
      state-store-mode = persistence
      buffer-size = 10000
      journal-plugin-id = "cassandra-journal"
      snapshot-plugin-id = "cassandra-snapshot-store"

      # Rebalance check is performed periodically with this interval
      rebalance-interval = 30 s

      snapshot-after = 7200
      waiting-for-state-timeout = 5 s
      updating-state-timeout = 5 s
    }

    #https://github.com/akka/akka-management/blob/master/cluster-http/src/main/resources/reference.conf
    management {
      # registers bootstrap routes to be included in akka-management's http endpoint
      # http.route-providers += "akka.management.cluster.ClusterHttpManagementRouteProvider"
      cluster.http {
        #host = 0.0.0.0
        port = 8558
      }
    }

  }

  persistence {
    journal {
      max-message-batch-size = 200
      max-confirmation-batch-size = 10000
      max-deletion-batch-size = 10000
      plugin = "cassandra-journal"
    }

    snapshot-store {
      plugin = "cassandra-snapshot-store"
    }

    ##
    at-least-once-delivery {
      # Interval between re-delivery attempts.
      redeliver-interval = 5s
      # Maximum number of unconfirmed messages that will be sent in one
      # re-delivery burst.
      redelivery-burst-limit = 10000
      # After this number of delivery attempts a
      # `ReliableRedelivery.UnconfirmedWarning`, message will be sent to the actor.
      warn-after-number-of-unconfirmed-attempts = 5
      # Maximum number of unconfirmed messages that an actor with
      # AtLeastOnceDelivery is allowed to hold in memory.
      max-unconfirmed-messages = 100000
    }

  }
}

//https://github.com/akka/akka-persistence-cassandra/blob/master/core/src/main/resources/reference.conf
cassandra-journal {

  #authentication.username = "fsa"
  #authentication.password = "..."

  # FQCN of the cassandra journal plugin
  class = "akka.persistence.cassandra.journal.CassandraJournal"

  # Comma-separated list of contact points in the cluster

  contact-points = [ "10.71.41.18" ] #"192.168.77.5"

  #contact-points = ["192.168.77.85"]

  # Port of contact points in the cluster
  port = 9042

  # Name of the keyspace to be created/used by the journal
  keyspace = "demo"

  # Name of the table to be created/used by the journal
  table = "demo_journal"

  # Replication factor to use when creating a keyspace
  replication-factor = 1

  #data-center-replication-factors = ["west:2", "east:2"]

  # Write consistency level
  write-consistency = "ONE"

  # Read consistency level
  read-consistency = "ONE"

  # Maximum number of entries per partition (= columns per row).
  target-partition-size = 4096

  # Maximum size of result set
  max-result-size = 50001

  # Maximum size of result set during replay
  max-result-size-replay = 50001

  # Dispatcher for the plugin actor.
  plugin-dispatcher = cassandra-dispatcher

  # Dispatcher for fetching and replaying messages
  replay-dispatcher = cassandra-dispatcher
}

cassandra-snapshot-store {

  #authentication.username = "fsa"
  #authentication.password = "..."

  # FQCN of the cassandra snapshot store plugin
  class = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"

  # Parameter indicating whether the journal keyspace should be auto created
  keyspace-autocreate = true

  # Parameter indicating whether the journal tables should be auto created
  tables-autocreate = true

  # Comma-separated list of contact points in the cluster

  contact-points = [ "10.71.41.18" ] #"192.168.77.5"

  # Port of contact points in the cluster
  port = 9042

  # Name of the keyspace to be created/used by the snapshot store
  keyspace = "demo"

  # Name of the table to be created/used by the snapshot store
  table = "demo_snapshot"

  # Replication factor to use when creating a keyspace
  replication-factor = 1

  #data-center-replication-factors = ["west:2", "east:2"]

  # Write consistency level
  write-consistency = "QUORUM"

  # Read consistency level
  read-consistency = "QUORUM"

  # Maximum number of snapshot metadata to load per recursion (when trying to
  # find a snapshot that matches specified selection criteria). Only increase
  # this value when selection criteria frequently select snapshots that are
  # much older than the most recent snapshot i.e. if there are much more than
  # 10 snapshots between the most recent one and selected one. This setting is
  # only for increasing load efficiency of snapshots.
  max-metadata-result-size = 10

  # Dispatcher for the plugin actor.
  plugin-dispatcher = cassandra-dispatcher
}

# https://github.com/akka/akka-persistence-cassandra/blob/master/core/src/main/resources/reference.conf
cassandra-query-journal {

  #authentication.username = "fsa"
  #authentication.password = "ncXMbELjuDycnokVhnQowLaFzcsPfnRJrmgTAeRmxouuexrcQFdx3mBPzcJNawEy"

  # New events are retrieved (polled) with this interval.
  refresh-interval = 3s

  # How many events to fetch in one query (replay) and keep buffered until they are delivered downstreams.
  max-buffer-size = 16

  # The fetch size of the Cassandra select statement
  # Value less or equal to 0 means max-result-size will be used
  # http://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/Statement.html
  max-result-size-query = 16

  # The number of retries when a read query fails.
  read-retries = 3
}

cassandra-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 2
    parallelism-max = 8
  }
}